{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research saved to research.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API 설정 (.env 파일에서 API 키 로드)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Wikipedia 검색 함수 (DuckDuckGo API Wrapper 사용)\n",
    "def search_wikipedia(query):\n",
    "    wrapper = DuckDuckGoSearchAPIWrapper(max_results=1)\n",
    "    wiki_query = WikipediaQueryRun(api_wrapper=wrapper)\n",
    "    result = wiki_query.run(query)\n",
    "    return result\n",
    "\n",
    "# DuckDuckGo 검색 함수 (예외 처리 추가, requests.exceptions.HTTPError 사용)\n",
    "def search_duckduckgo(query):\n",
    "    search = DuckDuckGoSearchAPIWrapper(max_results=3)\n",
    "    try:\n",
    "        results = search.run(query)\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        return f\"HTTPError occurred: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred during DuckDuckGo search: {str(e)}\"\n",
    "    return results\n",
    "\n",
    "# 수동 DuckDuckGo 검색 (백업 방법)\n",
    "def manual_duckduckgo_search(query):\n",
    "    url = f\"https://duckduckgo.com/html/?q={query}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        results = []\n",
    "        for result in soup.find_all(\"a\", class_=\"result__a\"):\n",
    "            title = result.get_text()\n",
    "            link = result.get(\"href\")\n",
    "            results.append({\"title\": title, \"url\": link})\n",
    "\n",
    "        return results\n",
    "    except requests.RequestException as e:\n",
    "        return f\"Error in manual DuckDuckGo search: {str(e)}\"\n",
    "\n",
    "# 웹사이트 스크래핑 함수\n",
    "def scrape_website(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        for header in soup.find_all([\"header\", \"footer\", \"nav\"]):\n",
    "            header.decompose()\n",
    "        content = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "        return content\n",
    "    except requests.RequestException as e:\n",
    "        return f\"Error scraping {url}: {str(e)}\"\n",
    "\n",
    "# GPT-4o-mini 모델로 질문에 답변 생성\n",
    "def ask_gpt(question, model=\"gpt-4o-mini\"):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "# 연구 결과를 .txt 파일로 저장하는 함수\n",
    "def save_research_to_file(content, filename=\"research.txt\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    print(f\"Research saved to {filename}\")\n",
    "\n",
    "# 에이전트 실행 함수\n",
    "def run_research_agent(query):\n",
    "    # 1. Wikipedia 검색\n",
    "    wiki_result = search_wikipedia(query)\n",
    "    research_content = f\"### Wikipedia Search Result:\\n\\n{wiki_result}\\n\\n\"\n",
    "\n",
    "    # 2. DuckDuckGo 검색 (예외 처리)\n",
    "    ddg_results = search_duckduckgo(query)\n",
    "    if isinstance(ddg_results, str):\n",
    "        # DuckDuckGo 검색이 실패했을 경우 (에러 메시지)\n",
    "        research_content += f\"### DuckDuckGo Search Results:\\nError: {ddg_results}\\n\"\n",
    "    else:\n",
    "        research_content += \"### DuckDuckGo Search Results:\\n\"\n",
    "        for idx, result in enumerate(ddg_results):\n",
    "            research_content += f\"{idx+1}. {result['title']}: {result['url']}\\n\"\n",
    "\n",
    "        # 3. 첫 번째 DuckDuckGo 검색 결과로부터 웹사이트 스크래핑\n",
    "        if ddg_results:\n",
    "            first_result_url = ddg_results[0]['url']\n",
    "            scraped_content = scrape_website(first_result_url)\n",
    "            research_content += f\"\\n### Scraped Content from {first_result_url}:\\n\\n{scraped_content}\\n\"\n",
    "\n",
    "    # 4. GPT-4o-mini 모델을 사용해 최종 답변 생성\n",
    "    gpt_response = ask_gpt(f\"Based on this research, can you summarize the findings about {query}?\", model=\"gpt-4o-mini\")\n",
    "    research_content += f\"\\n### GPT-4o-mini Summary:\\n\\n{gpt_response}\\n\"\n",
    "\n",
    "    # 5. 결과를 .txt 파일에 저장\n",
    "    save_research_to_file(research_content)\n",
    "\n",
    "# 실행 쿼리\n",
    "query = \"Research about the XZ backdoor\"\n",
    "run_research_agent(query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
